{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142_class/512\n",
      "3099 664 664\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "grayscale = False\n",
    "\n",
    "# Types: 142_class, 6_class, multi_model\n",
    "dataset_type = '142_class'\n",
    "\n",
    "image_dimensions = (512, 512)\n",
    "data_subfolder_name = '../data'\n",
    "use_dataset_percent = 0.5\n",
    "\n",
    "# Legacy:\n",
    "train_set_size = int(6199 * use_dataset_percent)\n",
    "validation_set_size = int(1328 * use_dataset_percent)\n",
    "test_set_size = int(1328 * use_dataset_percent)\n",
    "\n",
    "# training_presets_subfolder_name = f'{dataset_type}/{str(image_dimensions[0])}_{str(int(use_dataset_percent * 100))}_{dataset_type}'\n",
    "training_presets_subfolder_name = f'{dataset_type}/{str(image_dimensions[0])}'\n",
    "\n",
    "print(training_presets_subfolder_name)\n",
    "print(train_set_size, validation_set_size, test_set_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- in general, there are 6 categories:\n",
    "  - anchor(0)   - \"long\"\n",
    "  - bolt(1)     - \"long\"\n",
    "  - nut(2)      - \"stubby\"\n",
    "  - screw(3)    - \"long\"\n",
    "  - washer(4)   - \"stubby\"\n",
    "  - other(5)    - \"variable\"\n",
    "\n",
    "- balanced = the minimum amount of samples is in category #6, so we will adjust to it so we have an equal amount of samples in each category for now\n",
    "- the training set will be 70% of the data, the validation and test will each be 15%\n",
    "  - balanced = we use 8855 samples, which is only 52.18% of the dataset\n",
    "  - x_unbalanced = x marks the percentage of the full dataset used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in the folder: 1676\n",
      "Number of files in the folder: 6078\n",
      "Number of files in the folder: 1860\n",
      "Number of files in the folder: 4079\n",
      "Number of files in the folder: 1802\n",
      "Number of files in the folder: 1476\n"
     ]
    }
   ],
   "source": [
    "def count_files_in_folder(folder_path):\n",
    "    file_count = 0\n",
    "    \n",
    "    for item in os.listdir(folder_path):\n",
    "        if os.path.isfile(os.path.join(folder_path, item)):\n",
    "            file_count += 1\n",
    "    \n",
    "    return file_count\n",
    "\n",
    "folder_path = f'{data_subfolder_name}/0'  \n",
    "num_files = count_files_in_folder(folder_path)\n",
    "print(\"Number of files in the folder:\", num_files)\n",
    "\n",
    "folder_path = f'{data_subfolder_name}/1'  \n",
    "num_files = count_files_in_folder(folder_path)\n",
    "print(\"Number of files in the folder:\", num_files)\n",
    "\n",
    "folder_path = f'{data_subfolder_name}/2'  \n",
    "num_files = count_files_in_folder(folder_path)\n",
    "print(\"Number of files in the folder:\", num_files)\n",
    "\n",
    "folder_path = f'{data_subfolder_name}/3'  \n",
    "num_files = count_files_in_folder(folder_path)\n",
    "print(\"Number of files in the folder:\", num_files)\n",
    "\n",
    "folder_path = f'{data_subfolder_name}/4'  \n",
    "num_files = count_files_in_folder(folder_path)\n",
    "print(\"Number of files in the folder:\", num_files)\n",
    "\n",
    "folder_path = f'{data_subfolder_name}/5'  \n",
    "num_files = count_files_in_folder(folder_path)\n",
    "print(\"Number of files in the folder:\", num_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 142_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datumaro as dm\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "dataset = dm.Dataset.import_from('../../fastener_dataset/annotations/instances_default.json', format='coco')\n",
    "#stats = compute_ann_statistics(dataset)\n",
    "#print(dataset)\n",
    "\n",
    "# dataset_iter = iter(dataset)\n",
    "dataset_list = list(dataset)\n",
    "\n",
    "data = { }\n",
    " \n",
    "for i in range(0, 16970):\n",
    "    #print('processing image... ', i)\n",
    "    item = dataset_list[i]\n",
    "    item_annotation = item.annotations[0]\n",
    "    \n",
    "    new_path = item.media.path.replace(':', '_')\n",
    "    # item_img = cv2.imread(new_path)\n",
    "    # item_img = cv2.cvtColor(item_img, cv2.COLOR_BGR2RGB)\n",
    "    # res = cv2.resize(item_img, dsize=(224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    item_category = str(item_annotation.as_dict()['attributes']['category'])\n",
    "    # print('annotation: ', item_category)\n",
    "    \n",
    "    # images.append(res)\n",
    "    # labels.append(item_label)\n",
    "    \n",
    "    if(data.get(item_category) == None):\n",
    "        data[item_category] = []\n",
    "    data[item_category].append(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['667', '626', '595', '581', '533', '491', '475', '441', '433', '427', '414', '403', '351', '348', '298', '290', '281', '278', '272', '250', '249', '223', '217', '211', '207', '183', '178', '177', '172', '168', '591', '534', '495', '492', '469', '380', '370', '305', '304', '302', '301', '300', '256', '253', '243', '242', '201', '193', '155', '144', '139', '132', '130', '126', '125', '119', '118', '115', '109', '108', '107', '106', '103', '668', '666', '665', '664', '663', '575', '538', '486', '483', '465', '460', '398', '397', '352', '329', '246', '245', '237', '233', '231', '224', '216', '215', '214', '213', '212', '209', '196', '195', '194', '142', '452', '381', '324', '323', '3221', '322', '317', '316', '3155', '315', '314', '3106', '310', '624', '421', '419', '413', '411', '405', '295', '294', '293', '270', '269', '268', '267', '265', '264', '262', '261', '260', '259', '258', '547', '392', '369', '368', '358', '357', '346', '335', '333', '232', '220', '190', '189', '147', '137'])\n",
      "Minimum: 12\n",
      "Maximum: 582\n",
      "Average: 119.50704225352112\n",
      "Median: 72.0\n",
      "Total: 16970\n",
      "Adjusted total with threshold 100: 9427\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import statistics\n",
    "\n",
    "print(data.keys())\n",
    "\n",
    "total_count = 0\n",
    "adjusted_count = 0\n",
    "adjusted_threshold = 100\n",
    "counts = []\n",
    "count_dict = {}\n",
    "\n",
    "minimum = 17000\n",
    "maximum = 0\n",
    "\n",
    "for k, v in data.items():\n",
    "    count_dict[k] = len(v)\n",
    "    total_count += len(v)\n",
    "    if len(v) < minimum:\n",
    "        minimum = len(v)\n",
    "    if len(v) > maximum:\n",
    "        maximum = len(v)\n",
    "    adjusted_count += min(len(v), adjusted_threshold)\n",
    "    counts.append(len(v))\n",
    "\n",
    "average_len = total_count / len(data.keys())\n",
    "median_len = statistics.median(counts)\n",
    "\n",
    "print(f'Minimum: {minimum}')\n",
    "print(f'Maximum: {maximum}')\n",
    "print(f'Average: {average_len}')\n",
    "print(f'Median: {median_len}')\n",
    "print(f'Total: {total_count}')\n",
    "print(f'Adjusted total with threshold {adjusted_threshold}: {adjusted_count}')\n",
    "\n",
    "# with open('./datasets/category_count.json', 'w') as file:\n",
    "#     file.write(json.dumps(count_dict))\n",
    "\n",
    "# Min samples for category: 12, Max samples for category: 582"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Single Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category 667 with 72 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category 626 with 48 images...\n",
      "Category 595 with 12 images...\n",
      "Category 581 with 61 images...\n",
      "Category 533 with 120 images...\n",
      "Category 491 with 84 images...\n",
      "Category 475 with 24 images...\n",
      "Category 441 with 25 images...\n",
      "Category 433 with 36 images...\n",
      "Category 427 with 12 images...\n",
      "Category 414 with 24 images...\n",
      "Category 403 with 24 images...\n",
      "Category 351 with 60 images...\n",
      "Category 348 with 24 images...\n",
      "Category 298 with 48 images...\n",
      "Category 290 with 72 images...\n",
      "Category 281 with 36 images...\n",
      "Category 278 with 24 images...\n",
      "Category 272 with 72 images...\n",
      "Category 250 with 48 images...\n",
      "Category 249 with 24 images...\n",
      "Category 223 with 12 images...\n",
      "Category 217 with 48 images...\n",
      "Category 211 with 47 images...\n",
      "Category 207 with 144 images...\n",
      "Category 183 with 204 images...\n",
      "Category 178 with 24 images...\n",
      "Category 177 with 52 images...\n",
      "Category 172 with 234 images...\n",
      "Category 168 with 24 images...\n",
      "Category 591 with 24 images...\n",
      "Category 534 with 132 images...\n",
      "Category 495 with 336 images...\n",
      "Category 492 with 12 images...\n",
      "Category 469 with 582 images...\n",
      "Category 380 with 96 images...\n",
      "Category 370 with 70 images...\n",
      "Category 305 with 48 images...\n",
      "Category 304 with 168 images...\n",
      "Category 302 with 24 images...\n",
      "Category 301 with 120 images...\n",
      "Category 300 with 108 images...\n",
      "Category 256 with 315 images...\n",
      "Category 253 with 407 images...\n",
      "Category 243 with 24 images...\n",
      "Category 242 with 289 images...\n",
      "Category 201 with 468 images...\n",
      "Category 193 with 36 images...\n",
      "Category 155 with 288 images...\n",
      "Category 144 with 36 images...\n",
      "Category 139 with 84 images...\n",
      "Category 132 with 12 images...\n",
      "Category 130 with 372 images...\n",
      "Category 126 with 391 images...\n",
      "Category 125 with 514 images...\n",
      "Category 119 with 132 images...\n",
      "Category 118 with 432 images...\n",
      "Category 115 with 48 images...\n",
      "Category 109 with 24 images...\n",
      "Category 108 with 72 images...\n",
      "Category 107 with 18 images...\n",
      "Category 106 with 36 images...\n",
      "Category 103 with 215 images...\n",
      "Category 668 with 36 images...\n",
      "Category 666 with 24 images...\n",
      "Category 665 with 132 images...\n",
      "Category 664 with 132 images...\n",
      "Category 663 with 120 images...\n",
      "Category 575 with 144 images...\n",
      "Category 538 with 12 images...\n",
      "Category 486 with 72 images...\n",
      "Category 483 with 24 images...\n",
      "Category 465 with 58 images...\n",
      "Category 460 with 228 images...\n",
      "Category 398 with 24 images...\n",
      "Category 397 with 24 images...\n",
      "Category 352 with 372 images...\n",
      "Category 329 with 180 images...\n",
      "Category 246 with 12 images...\n",
      "Category 245 with 36 images...\n",
      "Category 237 with 24 images...\n",
      "Category 233 with 60 images...\n",
      "Category 231 with 192 images...\n",
      "Category 224 with 108 images...\n",
      "Category 216 with 241 images...\n",
      "Category 215 with 372 images...\n",
      "Category 214 with 193 images...\n",
      "Category 213 with 180 images...\n",
      "Category 212 with 204 images...\n",
      "Category 209 with 132 images...\n",
      "Category 196 with 36 images...\n",
      "Category 195 with 180 images...\n",
      "Category 194 with 120 images...\n",
      "Category 142 with 360 images...\n",
      "Category 452 with 216 images...\n",
      "Category 381 with 36 images...\n",
      "Category 324 with 180 images...\n",
      "Category 323 with 36 images...\n",
      "Category 3221 with 144 images...\n",
      "Category 322 with 110 images...\n",
      "Category 317 with 300 images...\n",
      "Category 316 with 24 images...\n",
      "Category 3155 with 331 images...\n",
      "Category 315 with 48 images...\n",
      "Category 314 with 72 images...\n",
      "Category 3106 with 36 images...\n",
      "Category 310 with 143 images...\n",
      "Category 624 with 24 images...\n",
      "Category 421 with 12 images...\n",
      "Category 419 with 24 images...\n",
      "Category 413 with 24 images...\n",
      "Category 411 with 24 images...\n",
      "Category 405 with 120 images...\n",
      "Category 295 with 24 images...\n",
      "Category 294 with 24 images...\n",
      "Category 293 with 120 images...\n",
      "Category 270 with 60 images...\n",
      "Category 269 with 72 images...\n",
      "Category 268 with 396 images...\n",
      "Category 267 with 72 images...\n",
      "Category 265 with 60 images...\n",
      "Category 264 with 156 images...\n",
      "Category 262 with 36 images...\n",
      "Category 261 with 72 images...\n",
      "Category 260 with 252 images...\n",
      "Category 259 with 48 images...\n",
      "Category 258 with 168 images...\n",
      "Category 547 with 36 images...\n",
      "Category 392 with 252 images...\n",
      "Category 369 with 96 images...\n",
      "Category 368 with 72 images...\n",
      "Category 358 with 72 images...\n",
      "Category 357 with 132 images...\n",
      "Category 346 with 48 images...\n",
      "Category 335 with 168 images...\n",
      "Category 333 with 108 images...\n",
      "Category 232 with 60 images...\n",
      "Category 220 with 156 images...\n",
      "Category 190 with 108 images...\n",
      "Category 189 with 308 images...\n",
      "Category 147 with 72 images...\n",
      "Category 137 with 114 images...\n",
      "\t 1  /  142\n",
      "\t 2  /  142\n",
      "\t 3  /  142\n",
      "\t 4  /  142\n",
      "\t 5  /  142\n",
      "\t 6  /  142\n",
      "\t 7  /  142\n",
      "\t 8  /  142\n",
      "\t 9  /  142\n",
      "\t 10  /  142\n",
      "\t 11  /  142\n",
      "\t 12  /  142\n",
      "\t 13  /  142\n",
      "\t 14  /  142\n",
      "\t 15  /  142\n",
      "\t 16  /  142\n",
      "\t 17  /  142\n",
      "\t 18  /  142\n",
      "\t 19  /  142\n",
      "\t 20  /  142\n",
      "\t 21  /  142\n",
      "\t 22  /  142\n",
      "\t 23  /  142\n",
      "\t 24  /  142\n",
      "\t 25  /  142\n",
      "\t 26  /  142\n",
      "\t 27  /  142\n",
      "\t 28  /  142\n",
      "\t 29  /  142\n",
      "\t 30  /  142\n",
      "\t 31  /  142\n",
      "\t 32  /  142\n",
      "\t 33  /  142\n",
      "\t 34  /  142\n",
      "\t 35  /  142\n",
      "\t 36  /  142\n",
      "\t 37  /  142\n",
      "\t 38  /  142\n",
      "\t 39  /  142\n",
      "\t 40  /  142\n",
      "\t 41  /  142\n",
      "\t 42  /  142\n",
      "\t 43  /  142\n",
      "\t 44  /  142\n",
      "\t 45  /  142\n",
      "\t 46  /  142\n",
      "\t 47  /  142\n",
      "\t 48  /  142\n",
      "\t 49  /  142\n",
      "\t 50  /  142\n",
      "\t 51  /  142\n",
      "\t 52  /  142\n",
      "\t 53  /  142\n",
      "\t 54  /  142\n",
      "\t 55  /  142\n",
      "\t 56  /  142\n",
      "\t 57  /  142\n",
      "\t 58  /  142\n",
      "\t 59  /  142\n",
      "\t 60  /  142\n",
      "\t 61  /  142\n",
      "\t 62  /  142\n",
      "\t 63  /  142\n",
      "\t 64  /  142\n",
      "\t 65  /  142\n",
      "\t 66  /  142\n",
      "\t 67  /  142\n",
      "\t 68  /  142\n",
      "\t 69  /  142\n",
      "\t 70  /  142\n",
      "\t 71  /  142\n",
      "\t 72  /  142\n",
      "\t 73  /  142\n",
      "\t 74  /  142\n",
      "\t 75  /  142\n",
      "\t 76  /  142\n",
      "\t 77  /  142\n",
      "\t 78  /  142\n",
      "\t 79  /  142\n",
      "\t 80  /  142\n",
      "\t 81  /  142\n",
      "\t 82  /  142\n",
      "\t 83  /  142\n",
      "\t 84  /  142\n",
      "\t 85  /  142\n",
      "\t 86  /  142\n",
      "\t 87  /  142\n",
      "\t 88  /  142\n",
      "\t 89  /  142\n",
      "\t 90  /  142\n",
      "\t 91  /  142\n",
      "\t 92  /  142\n",
      "\t 93  /  142\n",
      "\t 94  /  142\n",
      "\t 95  /  142\n",
      "\t 96  /  142\n",
      "\t 97  /  142\n",
      "\t 98  /  142\n",
      "\t 99  /  142\n",
      "\t 100  /  142\n",
      "\t 101  /  142\n",
      "\t 102  /  142\n",
      "\t 103  /  142\n",
      "\t 104  /  142\n",
      "\t 105  /  142\n",
      "\t 106  /  142\n",
      "\t 107  /  142\n",
      "\t 108  /  142\n",
      "\t 109  /  142\n",
      "\t 110  /  142\n",
      "\t 111  /  142\n",
      "\t 112  /  142\n",
      "\t 113  /  142\n",
      "\t 114  /  142\n",
      "\t 115  /  142\n",
      "\t 116  /  142\n",
      "\t 117  /  142\n",
      "\t 118  /  142\n",
      "\t 119  /  142\n",
      "\t 120  /  142\n",
      "\t 121  /  142\n",
      "\t 122  /  142\n",
      "\t 123  /  142\n",
      "\t 124  /  142\n",
      "\t 125  /  142\n",
      "\t 126  /  142\n",
      "\t 127  /  142\n",
      "\t 128  /  142\n",
      "\t 129  /  142\n",
      "\t 130  /  142\n",
      "\t 131  /  142\n",
      "\t 132  /  142\n",
      "\t 133  /  142\n",
      "\t 134  /  142\n",
      "\t 135  /  142\n",
      "\t 136  /  142\n",
      "\t 137  /  142\n",
      "\t 138  /  142\n",
      "\t 139  /  142\n",
      "\t 140  /  142\n",
      "\t 141  /  142\n",
      "\t 142  /  142\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Parallel:\n",
    "import concurrent.futures\n",
    "\n",
    "def process_images(category, image_paths):\n",
    "    processed_images = []\n",
    "    for image_path in image_paths:\n",
    "        image = cv2.imread(image_path)\n",
    "        if grayscale is True:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            resized = cv2.resize(image, dsize=image_dimensions, interpolation=cv2.INTER_CUBIC)\n",
    "            resized = np.expand_dims(resized, axis=-1)\n",
    "        else:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            resized = cv2.resize(image, dsize=image_dimensions, interpolation=cv2.INTER_CUBIC)\n",
    "        processed_images.append((resized, category))\n",
    "    return processed_images\n",
    "\n",
    "def create_dataset():\n",
    "    dataset = []\n",
    "\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for category in data.keys():\n",
    "            random.shuffle(data[category])\n",
    "            print(f'Category {category} with {len(data[category])} images...')\n",
    "            futures.append(executor.submit(process_images, category, data[category][:len(data[category])//2]))\n",
    "\n",
    "        for count, future in enumerate(concurrent.futures.as_completed(futures), 1):\n",
    "            dataset.extend(future.result())\n",
    "            print('\\t', count, ' / ', len(data.keys()))\n",
    "\n",
    "    random.shuffle(dataset)\n",
    "    return dataset\n",
    "\n",
    "dataset = create_dataset()\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving dataset...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "if grayscale is True:\n",
    "    dataset_filpeath = f\"./datasets/{training_presets_subfolder_name}/full_dataset_grayscale.pkl\"\n",
    "    with open(dataset_filpeath, \"wb\") as file:\n",
    "        print('Saving dataset...')\n",
    "        pickle.dump(dataset, file)\n",
    "        print('Done!')\n",
    "else:\n",
    "    dataset_filpeath = f\"./datasets/{training_presets_subfolder_name}/full_dataset.pkl\"\n",
    "    with open(dataset_filpeath, \"wb\") as file:\n",
    "        print('Saving dataset...')\n",
    "        pickle.dump(dataset, file)\n",
    "        print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create 3 Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing category 667 with 72 / 72 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 1  /  142\n",
      "processing category 626 with 48 / 48 images...\n",
      "\t 2  /  142\n",
      "processing category 595 with 12 / 12 images...\n",
      "\t 3  /  142\n",
      "processing category 581 with 61 / 61 images...\n",
      "\t 4  /  142\n",
      "processing category 533 with 100 / 120 images...\n",
      "\t 5  /  142\n",
      "processing category 491 with 84 / 84 images...\n",
      "\t 6  /  142\n",
      "processing category 475 with 24 / 24 images...\n",
      "\t 7  /  142\n",
      "processing category 441 with 25 / 25 images...\n",
      "\t 8  /  142\n",
      "processing category 433 with 36 / 36 images...\n",
      "\t 9  /  142\n",
      "processing category 427 with 12 / 12 images...\n",
      "\t 10  /  142\n",
      "processing category 414 with 24 / 24 images...\n",
      "\t 11  /  142\n",
      "processing category 403 with 24 / 24 images...\n",
      "\t 12  /  142\n",
      "processing category 351 with 60 / 60 images...\n",
      "\t 13  /  142\n",
      "processing category 348 with 24 / 24 images...\n",
      "\t 14  /  142\n",
      "processing category 298 with 48 / 48 images...\n",
      "\t 15  /  142\n",
      "processing category 290 with 72 / 72 images...\n",
      "\t 16  /  142\n",
      "processing category 281 with 36 / 36 images...\n",
      "\t 17  /  142\n",
      "processing category 278 with 24 / 24 images...\n",
      "\t 18  /  142\n",
      "processing category 272 with 72 / 72 images...\n",
      "\t 19  /  142\n",
      "processing category 250 with 48 / 48 images...\n",
      "\t 20  /  142\n",
      "processing category 249 with 24 / 24 images...\n",
      "\t 21  /  142\n",
      "processing category 223 with 12 / 12 images...\n",
      "\t 22  /  142\n",
      "processing category 217 with 48 / 48 images...\n",
      "\t 23  /  142\n",
      "processing category 211 with 47 / 47 images...\n",
      "\t 24  /  142\n",
      "processing category 207 with 100 / 144 images...\n",
      "\t 25  /  142\n",
      "processing category 183 with 100 / 204 images...\n",
      "\t 26  /  142\n",
      "processing category 178 with 24 / 24 images...\n",
      "\t 27  /  142\n",
      "processing category 177 with 52 / 52 images...\n",
      "\t 28  /  142\n",
      "processing category 172 with 100 / 234 images...\n",
      "\t 29  /  142\n",
      "processing category 168 with 24 / 24 images...\n",
      "\t 30  /  142\n",
      "processing category 591 with 24 / 24 images...\n",
      "\t 31  /  142\n",
      "processing category 534 with 100 / 132 images...\n",
      "\t 32  /  142\n",
      "processing category 495 with 100 / 336 images...\n",
      "\t 33  /  142\n",
      "processing category 492 with 12 / 12 images...\n",
      "\t 34  /  142\n",
      "processing category 469 with 100 / 582 images...\n",
      "\t 35  /  142\n",
      "processing category 380 with 96 / 96 images...\n",
      "\t 36  /  142\n",
      "processing category 370 with 70 / 70 images...\n",
      "\t 37  /  142\n",
      "processing category 305 with 48 / 48 images...\n",
      "\t 38  /  142\n",
      "processing category 304 with 100 / 168 images...\n",
      "\t 39  /  142\n",
      "processing category 302 with 24 / 24 images...\n",
      "\t 40  /  142\n",
      "processing category 301 with 100 / 120 images...\n",
      "\t 41  /  142\n",
      "processing category 300 with 100 / 108 images...\n",
      "\t 42  /  142\n",
      "processing category 256 with 100 / 315 images...\n",
      "\t 43  /  142\n",
      "processing category 253 with 100 / 407 images...\n",
      "\t 44  /  142\n",
      "processing category 243 with 24 / 24 images...\n",
      "\t 45  /  142\n",
      "processing category 242 with 100 / 289 images...\n",
      "\t 46  /  142\n",
      "processing category 201 with 100 / 468 images...\n",
      "\t 47  /  142\n",
      "processing category 193 with 36 / 36 images...\n",
      "\t 48  /  142\n",
      "processing category 155 with 100 / 288 images...\n",
      "\t 49  /  142\n",
      "processing category 144 with 36 / 36 images...\n",
      "\t 50  /  142\n",
      "processing category 139 with 84 / 84 images...\n",
      "\t 51  /  142\n",
      "processing category 132 with 12 / 12 images...\n",
      "\t 52  /  142\n",
      "processing category 130 with 100 / 372 images...\n",
      "\t 53  /  142\n",
      "processing category 126 with 100 / 391 images...\n",
      "\t 54  /  142\n",
      "processing category 125 with 100 / 514 images...\n",
      "\t 55  /  142\n",
      "processing category 119 with 100 / 132 images...\n",
      "\t 56  /  142\n",
      "processing category 118 with 100 / 432 images...\n",
      "\t 57  /  142\n",
      "processing category 115 with 48 / 48 images...\n",
      "\t 58  /  142\n",
      "processing category 109 with 24 / 24 images...\n",
      "\t 59  /  142\n",
      "processing category 108 with 72 / 72 images...\n",
      "\t 60  /  142\n",
      "processing category 107 with 18 / 18 images...\n",
      "\t 61  /  142\n",
      "processing category 106 with 36 / 36 images...\n",
      "\t 62  /  142\n",
      "processing category 103 with 100 / 215 images...\n",
      "\t 63  /  142\n",
      "processing category 668 with 36 / 36 images...\n",
      "\t 64  /  142\n",
      "processing category 666 with 24 / 24 images...\n",
      "\t 65  /  142\n",
      "processing category 665 with 100 / 132 images...\n",
      "\t 66  /  142\n",
      "processing category 664 with 100 / 132 images...\n",
      "\t 67  /  142\n",
      "processing category 663 with 100 / 120 images...\n",
      "\t 68  /  142\n",
      "processing category 575 with 100 / 144 images...\n",
      "\t 69  /  142\n",
      "processing category 538 with 12 / 12 images...\n",
      "\t 70  /  142\n",
      "processing category 486 with 72 / 72 images...\n",
      "\t 71  /  142\n",
      "processing category 483 with 24 / 24 images...\n",
      "\t 72  /  142\n",
      "processing category 465 with 58 / 58 images...\n",
      "\t 73  /  142\n",
      "processing category 460 with 100 / 228 images...\n",
      "\t 74  /  142\n",
      "processing category 398 with 24 / 24 images...\n",
      "\t 75  /  142\n",
      "processing category 397 with 24 / 24 images...\n",
      "\t 76  /  142\n",
      "processing category 352 with 100 / 372 images...\n",
      "\t 77  /  142\n",
      "processing category 329 with 100 / 180 images...\n",
      "\t 78  /  142\n",
      "processing category 246 with 12 / 12 images...\n",
      "\t 79  /  142\n",
      "processing category 245 with 36 / 36 images...\n",
      "\t 80  /  142\n",
      "processing category 237 with 24 / 24 images...\n",
      "\t 81  /  142\n",
      "processing category 233 with 60 / 60 images...\n",
      "\t 82  /  142\n",
      "processing category 231 with 100 / 192 images...\n",
      "\t 83  /  142\n",
      "processing category 224 with 100 / 108 images...\n",
      "\t 84  /  142\n",
      "processing category 216 with 100 / 241 images...\n",
      "\t 85  /  142\n",
      "processing category 215 with 100 / 372 images...\n",
      "\t 86  /  142\n",
      "processing category 214 with 100 / 193 images...\n",
      "\t 87  /  142\n",
      "processing category 213 with 100 / 180 images...\n",
      "\t 88  /  142\n",
      "processing category 212 with 100 / 204 images...\n",
      "\t 89  /  142\n",
      "processing category 209 with 100 / 132 images...\n",
      "\t 90  /  142\n",
      "processing category 196 with 36 / 36 images...\n",
      "\t 91  /  142\n",
      "processing category 195 with 100 / 180 images...\n",
      "\t 92  /  142\n",
      "processing category 194 with 100 / 120 images...\n",
      "\t 93  /  142\n",
      "processing category 142 with 100 / 360 images...\n",
      "\t 94  /  142\n",
      "processing category 452 with 100 / 216 images...\n",
      "\t 95  /  142\n",
      "processing category 381 with 36 / 36 images...\n",
      "\t 96  /  142\n",
      "processing category 324 with 100 / 180 images...\n",
      "\t 97  /  142\n",
      "processing category 323 with 36 / 36 images...\n",
      "\t 98  /  142\n",
      "processing category 3221 with 100 / 144 images...\n",
      "\t 99  /  142\n",
      "processing category 322 with 100 / 110 images...\n",
      "\t 100  /  142\n",
      "processing category 317 with 100 / 300 images...\n",
      "\t 101  /  142\n",
      "processing category 316 with 24 / 24 images...\n",
      "\t 102  /  142\n",
      "processing category 3155 with 100 / 331 images...\n",
      "\t 103  /  142\n",
      "processing category 315 with 48 / 48 images...\n",
      "\t 104  /  142\n",
      "processing category 314 with 72 / 72 images...\n",
      "\t 105  /  142\n",
      "processing category 3106 with 36 / 36 images...\n",
      "\t 106  /  142\n",
      "processing category 310 with 100 / 143 images...\n",
      "\t 107  /  142\n",
      "processing category 624 with 24 / 24 images...\n",
      "\t 108  /  142\n",
      "processing category 421 with 12 / 12 images...\n",
      "\t 109  /  142\n",
      "processing category 419 with 24 / 24 images...\n",
      "\t 110  /  142\n",
      "processing category 413 with 24 / 24 images...\n",
      "\t 111  /  142\n",
      "processing category 411 with 24 / 24 images...\n",
      "\t 112  /  142\n",
      "processing category 405 with 100 / 120 images...\n",
      "\t 113  /  142\n",
      "processing category 295 with 24 / 24 images...\n",
      "\t 114  /  142\n",
      "processing category 294 with 24 / 24 images...\n",
      "\t 115  /  142\n",
      "processing category 293 with 100 / 120 images...\n",
      "\t 116  /  142\n",
      "processing category 270 with 60 / 60 images...\n",
      "\t 117  /  142\n",
      "processing category 269 with 72 / 72 images...\n",
      "\t 118  /  142\n",
      "processing category 268 with 100 / 396 images...\n",
      "\t 119  /  142\n",
      "processing category 267 with 72 / 72 images...\n",
      "\t 120  /  142\n",
      "processing category 265 with 60 / 60 images...\n",
      "\t 121  /  142\n",
      "processing category 264 with 100 / 156 images...\n",
      "\t 122  /  142\n",
      "processing category 262 with 36 / 36 images...\n",
      "\t 123  /  142\n",
      "processing category 261 with 72 / 72 images...\n",
      "\t 124  /  142\n",
      "processing category 260 with 100 / 252 images...\n",
      "\t 125  /  142\n",
      "processing category 259 with 48 / 48 images...\n",
      "\t 126  /  142\n",
      "processing category 258 with 100 / 168 images...\n",
      "\t 127  /  142\n",
      "processing category 547 with 36 / 36 images...\n",
      "\t 128  /  142\n",
      "processing category 392 with 100 / 252 images...\n",
      "\t 129  /  142\n",
      "processing category 369 with 96 / 96 images...\n",
      "\t 130  /  142\n",
      "processing category 368 with 72 / 72 images...\n",
      "\t 131  /  142\n",
      "processing category 358 with 72 / 72 images...\n",
      "\t 132  /  142\n",
      "processing category 357 with 100 / 132 images...\n",
      "\t 133  /  142\n",
      "processing category 346 with 48 / 48 images...\n",
      "\t 134  /  142\n",
      "processing category 335 with 100 / 168 images...\n",
      "\t 135  /  142\n",
      "processing category 333 with 100 / 108 images...\n",
      "\t 136  /  142\n",
      "processing category 232 with 60 / 60 images...\n",
      "\t 137  /  142\n",
      "processing category 220 with 100 / 156 images...\n",
      "\t 138  /  142\n",
      "processing category 190 with 100 / 108 images...\n",
      "\t 139  /  142\n",
      "processing category 189 with 100 / 308 images...\n",
      "\t 140  /  142\n",
      "processing category 147 with 72 / 72 images...\n",
      "\t 141  /  142\n",
      "processing category 137 with 100 / 114 images...\n",
      "\t 142  /  142\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def create_dataset_slice(reduce_dataset: float = 1):\n",
    "    train_data = []\n",
    "    validation_data = []\n",
    "    test_data = []\n",
    "    \n",
    "    count = 0\n",
    "    for category in data.keys():\n",
    "        \n",
    "        random.shuffle(data[category])\n",
    "        cutoff = int(len(data[category]))\n",
    "        if int(len(data[category]) * reduce_dataset) > 100:\n",
    "            # cutoff = int(len(data[category]) * reduce_dataset)\n",
    "            cutoff = 100\n",
    "        print(f'processing category {category} with {cutoff} / {len(data[category])} images...')\n",
    "        data[category] = data[category][:cutoff+1]\n",
    "        \n",
    "        train_end = int(0.7 * len(data[category]))\n",
    "        val_end = int(0.85 * len(data[category]))\n",
    "        \n",
    "        for image_path in data[category][:train_end]:\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            resized = cv2.resize(image, dsize=image_dimensions, interpolation=cv2.INTER_CUBIC)\n",
    "            \n",
    "            train_data.append((resized, category))\n",
    "        for image_path in data[category][train_end:val_end]:\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            resized = cv2.resize(image, dsize=image_dimensions, interpolation=cv2.INTER_CUBIC)\n",
    "            \n",
    "            validation_data.append((resized, category))\n",
    "        for image_path in data[category][val_end:]:\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            resized = cv2.resize(image, dsize=image_dimensions, interpolation=cv2.INTER_CUBIC)\n",
    "            \n",
    "            test_data.append((resized, category))\n",
    "    \n",
    "        count += 1\n",
    "        print('\\t', count, ' / ', len(data.keys()))\n",
    "    \n",
    "    random.shuffle(train_data)\n",
    "    random.shuffle(validation_data)\n",
    "    random.shuffle(test_data)\n",
    "    \n",
    "    return train_data, validation_data, test_data\n",
    "\n",
    "\n",
    "train_set, validation_set, test_set = create_dataset_slice(use_dataset_percent)\n",
    "print('Done!')\n",
    "\n",
    "# (train_images, train_labels) = zip(*train_set)\n",
    "# (validation_images, validation_labels) = zip(*validation_set)\n",
    "# (test_images, test_labels) = zip(*test_set)\n",
    "\n",
    "# train_images = np.array(train_images)\n",
    "# train_labels = np.array(train_labels)\n",
    "# validation_images = np.array(validation_images)\n",
    "# validation_labels = np.array(validation_labels)\n",
    "# test_images = np.array(test_images)\n",
    "# test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving training set...\n",
      "Done!\n",
      "Saving validation set...\n",
      "Done!\n",
      "Saving test set...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "training_presets_subfolder_name = f'{dataset_type}/{str(image_dimensions[0])}'\n",
    "\n",
    "training_set_file_path = f\"./datasets/{training_presets_subfolder_name}/training_set.pkl\"\n",
    "validation_set_file_path = f\"./datasets/{training_presets_subfolder_name}/validation_set.pkl\"\n",
    "test_set_file_path = f\"./datasets/{training_presets_subfolder_name}/test_set.pkl\"\n",
    "\n",
    "with open(training_set_file_path, \"wb\") as file:\n",
    "    print('Saving training set...')\n",
    "    pickle.dump(train_set, file)\n",
    "    print('Done!')\n",
    "\n",
    "with open(validation_set_file_path, \"wb\") as file:\n",
    "    print('Saving validation set...')\n",
    "    pickle.dump(validation_set, file)\n",
    "    print('Done!')\n",
    "\n",
    "with open(test_set_file_path, \"wb\") as file:\n",
    "    print('Saving test set...')\n",
    "    pickle.dump(test_set, file)\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Experimental: Multithread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing category 667 with 72 / 72 images...\n",
      "\t 1  /  142\n",
      "processing category 626 with 48 / 48 images...\n",
      "\t 2  /  142\n",
      "processing category 595 with 12 / 12 images...\n",
      "\t 3  /  142\n",
      "processing category 581 with 61 / 61 images...\n",
      "\t 4  /  142\n",
      "processing category 533 with 30 / 120 images...\n",
      "\t 5  /  142\n",
      "processing category 491 with 84 / 84 images...\n",
      "\t 6  /  142\n",
      "processing category 475 with 24 / 24 images...\n",
      "\t 7  /  142\n",
      "processing category 441 with 25 / 25 images...\n",
      "\t 8  /  142\n",
      "processing category 433 with 36 / 36 images...\n",
      "\t 9  /  142\n",
      "processing category 427 with 12 / 12 images...\n",
      "\t 10  /  142\n",
      "processing category 414 with 24 / 24 images...\n",
      "\t 11  /  142\n",
      "processing category 403 with 24 / 24 images...\n",
      "\t 12  /  142\n",
      "processing category 351 with 60 / 60 images...\n",
      "\t 13  /  142\n",
      "processing category 348 with 24 / 24 images...\n",
      "\t 14  /  142\n",
      "processing category 298 with 48 / 48 images...\n",
      "\t 15  /  142\n",
      "processing category 290 with 72 / 72 images...\n",
      "\t 16  /  142\n",
      "processing category 281 with 36 / 36 images...\n",
      "\t 17  /  142\n",
      "processing category 278 with 24 / 24 images...\n",
      "\t 18  /  142\n",
      "processing category 272 with 72 / 72 images...\n",
      "\t 19  /  142\n",
      "processing category 250 with 48 / 48 images...\n",
      "\t 20  /  142\n",
      "processing category 249 with 24 / 24 images...\n",
      "\t 21  /  142\n",
      "processing category 223 with 12 / 12 images...\n",
      "\t 22  /  142\n",
      "processing category 217 with 48 / 48 images...\n",
      "\t 23  /  142\n",
      "processing category 211 with 47 / 47 images...\n",
      "\t 24  /  142\n",
      "processing category 207 with 36 / 144 images...\n",
      "\t 25  /  142\n",
      "processing category 183 with 51 / 204 images...\n",
      "\t 26  /  142\n",
      "processing category 178 with 24 / 24 images...\n",
      "\t 27  /  142\n",
      "processing category 177 with 52 / 52 images...\n",
      "\t 28  /  142\n",
      "processing category 172 with 58 / 234 images...\n",
      "\t 29  /  142\n",
      "processing category 168 with 24 / 24 images...\n",
      "\t 30  /  142\n",
      "processing category 591 with 24 / 24 images...\n",
      "\t 31  /  142\n",
      "processing category 534 with 33 / 132 images...\n",
      "\t 32  /  142\n",
      "processing category 495 with 84 / 336 images...\n",
      "\t 33  /  142\n",
      "processing category 492 with 12 / 12 images...\n",
      "\t 34  /  142\n",
      "processing category 469 with 145 / 582 images...\n",
      "\t 35  /  142\n",
      "processing category 380 with 96 / 96 images...\n",
      "\t 36  /  142\n",
      "processing category 370 with 70 / 70 images...\n",
      "\t 37  /  142\n",
      "processing category 305 with 48 / 48 images...\n",
      "\t 38  /  142\n",
      "processing category 304 with 42 / 168 images...\n",
      "\t 39  /  142\n",
      "processing category 302 with 24 / 24 images...\n",
      "\t 40  /  142\n",
      "processing category 301 with 30 / 120 images...\n",
      "\t 41  /  142\n",
      "processing category 300 with 27 / 108 images...\n",
      "\t 42  /  142\n",
      "processing category 256 with 78 / 315 images...\n",
      "\t 43  /  142\n",
      "processing category 253 with 101 / 407 images...\n",
      "\t 44  /  142\n",
      "processing category 243 with 24 / 24 images...\n",
      "\t 45  /  142\n",
      "processing category 242 with 72 / 289 images...\n",
      "\t 46  /  142\n",
      "processing category 201 with 117 / 468 images...\n",
      "\t 47  /  142\n",
      "processing category 193 with 36 / 36 images...\n",
      "\t 48  /  142\n",
      "processing category 155 with 72 / 288 images...\n",
      "\t 49  /  142\n",
      "processing category 144 with 36 / 36 images...\n",
      "\t 50  /  142\n",
      "processing category 139 with 84 / 84 images...\n",
      "\t 51  /  142\n",
      "processing category 132 with 12 / 12 images...\n",
      "\t 52  /  142\n",
      "processing category 130 with 93 / 372 images...\n",
      "\t 53  /  142\n",
      "processing category 126 with 97 / 391 images...\n",
      "\t 54  /  142\n",
      "processing category 125 with 128 / 514 images...\n",
      "\t 55  /  142\n",
      "processing category 119 with 33 / 132 images...\n",
      "\t 56  /  142\n",
      "processing category 118 with 108 / 432 images...\n",
      "\t 57  /  142\n",
      "processing category 115 with 48 / 48 images...\n",
      "\t 58  /  142\n",
      "processing category 109 with 24 / 24 images...\n",
      "\t 59  /  142\n",
      "processing category 108 with 72 / 72 images...\n",
      "\t 60  /  142\n",
      "processing category 107 with 18 / 18 images...\n",
      "\t 61  /  142\n",
      "processing category 106 with 36 / 36 images...\n",
      "\t 62  /  142\n",
      "processing category 103 with 53 / 215 images...\n",
      "\t 63  /  142\n",
      "processing category 668 with 36 / 36 images...\n",
      "\t 64  /  142\n",
      "processing category 666 with 24 / 24 images...\n",
      "\t 65  /  142\n",
      "processing category 665 with 33 / 132 images...\n",
      "\t 66  /  142\n",
      "processing category 664 with 33 / 132 images...\n",
      "\t 67  /  142\n",
      "processing category 663 with 30 / 120 images...\n",
      "\t 68  /  142\n",
      "processing category 575 with 36 / 144 images...\n",
      "\t 69  /  142\n",
      "processing category 538 with 12 / 12 images...\n",
      "\t 70  /  142\n",
      "processing category 486 with 72 / 72 images...\n",
      "\t 71  /  142\n",
      "processing category 483 with 24 / 24 images...\n",
      "\t 72  /  142\n",
      "processing category 465 with 58 / 58 images...\n",
      "\t 73  /  142\n",
      "processing category 460 with 57 / 228 images...\n",
      "\t 74  /  142\n",
      "processing category 398 with 24 / 24 images...\n",
      "\t 75  /  142\n",
      "processing category 397 with 24 / 24 images...\n",
      "\t 76  /  142\n",
      "processing category 352 with 93 / 372 images...\n",
      "\t 77  /  142\n",
      "processing category 329 with 45 / 180 images...\n",
      "\t 78  /  142\n",
      "processing category 246 with 12 / 12 images...\n",
      "\t 79  /  142\n",
      "processing category 245 with 36 / 36 images...\n",
      "\t 80  /  142\n",
      "processing category 237 with 24 / 24 images...\n",
      "\t 81  /  142\n",
      "processing category 233 with 60 / 60 images...\n",
      "\t 82  /  142\n",
      "processing category 231 with 48 / 192 images...\n",
      "\t 83  /  142\n",
      "processing category 224 with 27 / 108 images...\n",
      "\t 84  /  142\n",
      "processing category 216 with 60 / 241 images...\n",
      "\t 85  /  142\n",
      "processing category 215 with 93 / 372 images...\n",
      "\t 86  /  142\n",
      "processing category 214 with 48 / 193 images...\n",
      "\t 87  /  142\n",
      "processing category 213 with 45 / 180 images...\n",
      "\t 88  /  142\n",
      "processing category 212 with 51 / 204 images...\n",
      "\t 89  /  142\n",
      "processing category 209 with 33 / 132 images...\n",
      "\t 90  /  142\n",
      "processing category 196 with 36 / 36 images...\n",
      "\t 91  /  142\n",
      "processing category 195 with 45 / 180 images...\n",
      "\t 92  /  142\n",
      "processing category 194 with 30 / 120 images...\n",
      "\t 93  /  142\n",
      "processing category 142 with 90 / 360 images...\n",
      "\t 94  /  142\n",
      "processing category 452 with 54 / 216 images...\n",
      "\t 95  /  142\n",
      "processing category 381 with 36 / 36 images...\n",
      "\t 96  /  142\n",
      "processing category 324 with 45 / 180 images...\n",
      "\t 97  /  142\n",
      "processing category 323 with 36 / 36 images...\n",
      "\t 98  /  142\n",
      "processing category 3221 with 36 / 144 images...\n",
      "\t 99  /  142\n",
      "processing category 322 with 27 / 110 images...\n",
      "\t 100  /  142\n",
      "processing category 317 with 75 / 300 images...\n",
      "\t 101  /  142\n",
      "processing category 316 with 24 / 24 images...\n",
      "\t 102  /  142\n",
      "processing category 3155 with 82 / 331 images...\n",
      "\t 103  /  142\n",
      "processing category 315 with 48 / 48 images...\n",
      "\t 104  /  142\n",
      "processing category 314 with 72 / 72 images...\n",
      "\t 105  /  142\n",
      "processing category 3106 with 36 / 36 images...\n",
      "\t 106  /  142\n",
      "processing category 310 with 35 / 143 images...\n",
      "\t 107  /  142\n",
      "processing category 624 with 24 / 24 images...\n",
      "\t 108  /  142\n",
      "processing category 421 with 12 / 12 images...\n",
      "\t 109  /  142\n",
      "processing category 419 with 24 / 24 images...\n",
      "\t 110  /  142\n",
      "processing category 413 with 24 / 24 images...\n",
      "\t 111  /  142\n",
      "processing category 411 with 24 / 24 images...\n",
      "\t 112  /  142\n",
      "processing category 405 with 30 / 120 images...\n",
      "\t 113  /  142\n",
      "processing category 295 with 24 / 24 images...\n",
      "\t 114  /  142\n",
      "processing category 294 with 24 / 24 images...\n",
      "\t 115  /  142\n",
      "processing category 293 with 30 / 120 images...\n",
      "\t 116  /  142\n",
      "processing category 270 with 60 / 60 images...\n",
      "\t 117  /  142\n",
      "processing category 269 with 72 / 72 images...\n",
      "\t 118  /  142\n",
      "processing category 268 with 99 / 396 images...\n",
      "\t 119  /  142\n",
      "processing category 267 with 72 / 72 images...\n",
      "\t 120  /  142\n",
      "processing category 265 with 60 / 60 images...\n",
      "\t 121  /  142\n",
      "processing category 264 with 39 / 156 images...\n",
      "\t 122  /  142\n",
      "processing category 262 with 36 / 36 images...\n",
      "\t 123  /  142\n",
      "processing category 261 with 72 / 72 images...\n",
      "\t 124  /  142\n",
      "processing category 260 with 63 / 252 images...\n",
      "\t 125  /  142\n",
      "processing category 259 with 48 / 48 images...\n",
      "\t 126  /  142\n",
      "processing category 258 with 42 / 168 images...\n",
      "\t 127  /  142\n",
      "processing category 547 with 36 / 36 images...\n",
      "\t 128  /  142\n",
      "processing category 392 with 63 / 252 images...\n",
      "\t 129  /  142\n",
      "processing category 369 with 96 / 96 images...\n",
      "\t 130  /  142\n",
      "processing category 368 with 72 / 72 images...\n",
      "\t 131  /  142\n",
      "processing category 358 with 72 / 72 images...\n",
      "\t 132  /  142\n",
      "processing category 357 with 33 / 132 images...\n",
      "\t 133  /  142\n",
      "processing category 346 with 48 / 48 images...\n",
      "\t 134  /  142\n",
      "processing category 335 with 42 / 168 images...\n",
      "\t 135  /  142\n",
      "processing category 333 with 27 / 108 images...\n",
      "\t 136  /  142\n",
      "processing category 232 with 60 / 60 images...\n",
      "\t 137  /  142\n",
      "processing category 220 with 39 / 156 images...\n",
      "\t 138  /  142\n",
      "processing category 190 with 27 / 108 images...\n",
      "\t 139  /  142\n",
      "processing category 189 with 77 / 308 images...\n",
      "\t 140  /  142\n",
      "processing category 147 with 72 / 72 images...\n",
      "\t 141  /  142\n",
      "processing category 137 with 28 / 114 images...\n",
      "\t 142  /  142\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 46\u001b[0m, in \u001b[0;36mcreate_dataset_slice\u001b[0;34m(reduce_dataset)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m processed_images:\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mprocessed_images\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mcategory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcategory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprocessed_images\u001b[49m\u001b[43m]\u001b[49m:\n\u001b[1;32m     47\u001b[0m         train_data\u001b[38;5;241m.\u001b[39mextend(processed_images)\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 59\u001b[0m\n\u001b[1;32m     55\u001b[0m     random\u001b[38;5;241m.\u001b[39mshuffle(test_data)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m train_data, validation_data, test_data\n\u001b[0;32m---> 59\u001b[0m train_set, validation_set, test_set \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_dataset_slice\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_dataset_percent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# (train_images, train_labels) = zip(*train_set)\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# (validation_images, validation_labels) = zip(*validation_set)\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# (test_images, test_labels) = zip(*test_set)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# test_images = np.array(test_images)\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# test_labels = np.array(test_labels)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 20\u001b[0m, in \u001b[0;36mcreate_dataset_slice\u001b[0;34m(reduce_dataset)\u001b[0m\n\u001b[1;32m     17\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     18\u001b[0m futures \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 20\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mThreadPoolExecutor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcategory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcategory\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py:647\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 647\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.11/concurrent/futures/thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[0;32m--> 235\u001b[0m         \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.11/threading.py:1112\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1112\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1114\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m/usr/lib/python3.11/threading.py:1132\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1133\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "def process_images(image_paths, category):\n",
    "    processed_images = []\n",
    "    for image_path in image_paths:\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        resized = cv2.resize(image, dsize=image_dimensions, interpolation=cv2.INTER_CUBIC)\n",
    "        processed_images.append((resized, category))\n",
    "    return processed_images\n",
    "\n",
    "def create_dataset_slice(reduce_dataset: float = 1):\n",
    "    train_data = []\n",
    "    validation_data = []\n",
    "    test_data = []\n",
    "\n",
    "    count = 0\n",
    "    futures = []\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        for category in data.keys():\n",
    "            random.shuffle(data[category])\n",
    "            cutoff = int(len(data[category]))\n",
    "            if int(len(data[category]) * reduce_dataset) >= 25:\n",
    "                cutoff = int(len(data[category]) * reduce_dataset)\n",
    "            print(f'processing category {category} with {cutoff} / {len(data[category])} images...')\n",
    "            data[category] = data[category][:cutoff]\n",
    "\n",
    "            train_end = int(0.7 * len(data[category]))\n",
    "            val_end = int(0.85 * len(data[category]))\n",
    "\n",
    "            train_images = data[category][:train_end]\n",
    "            val_images = data[category][train_end:val_end]\n",
    "            test_images = data[category][val_end:]\n",
    "\n",
    "            futures.append(executor.submit(process_images, train_images, category))\n",
    "            futures.append(executor.submit(process_images, val_images, category))\n",
    "            futures.append(executor.submit(process_images, test_images, category))\n",
    "\n",
    "            count += 1\n",
    "            print('\\t', count, ' / ', len(data.keys()))\n",
    "\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            processed_images = future.result()\n",
    "            if processed_images:\n",
    "                if processed_images[0][1] in [category for category, _ in processed_images]:\n",
    "                    train_data.extend(processed_images)\n",
    "                elif processed_images[0][1] in [category for category, _ in processed_images]:\n",
    "                    validation_data.extend(processed_images)\n",
    "                else:\n",
    "                    test_data.extend(processed_images)\n",
    "\n",
    "    random.shuffle(train_data)\n",
    "    random.shuffle(validation_data)\n",
    "    random.shuffle(test_data)\n",
    "\n",
    "    return train_data, validation_data, test_data\n",
    "\n",
    "train_set, validation_set, test_set = create_dataset_slice(use_dataset_percent)\n",
    "print('Done!')\n",
    "\n",
    "# (train_images, train_labels) = zip(*train_set)\n",
    "# (validation_images, validation_labels) = zip(*validation_set)\n",
    "# (test_images, test_labels) = zip(*test_set)\n",
    "\n",
    "# train_images = np.array(train_images)\n",
    "# train_labels = np.array(train_labels)\n",
    "# validation_images = np.array(validation_images)\n",
    "# validation_labels = np.array(validation_labels)\n",
    "# test_images = np.array(test_images)\n",
    "# test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optional: Remove 'other' class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(dataset_filpeath, \"rb\") as file:\n",
    "  print('Loading dataset...')\n",
    "  dataset = pickle.load(file)\n",
    "  print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing training set...\n",
      "Done!\n",
      "16970\n",
      "15494\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('datasets/categories.json', 'r') as file:\n",
    "  categories = json.load(file)\n",
    "\n",
    "dataset_no_other = []\n",
    "\n",
    "print('Processing training set...')\n",
    "for sample in dataset:\n",
    "  if not int(sample[1]) in categories['5']:\n",
    "    dataset_no_other.append(sample)\n",
    "print('Done!')\n",
    "\n",
    "    \n",
    "print(len(dataset))\n",
    "print(len(dataset_no_other))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving dataset...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset_no_other_filepath = f\"./datasets/{training_presets_subfolder_name}/full_dataset_NO_OTHER.pkl\"\n",
    "\n",
    "with open(dataset_no_other_filepath, \"wb\") as file:\n",
    "    print('Saving dataset...')\n",
    "    pickle.dump(dataset_no_other, file)\n",
    "    print('Done!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_presets_subfolder_name = f'{dataset_type}/{str(image_dimensions[0])}_{str(int(use_dataset_percent * 100))}_{dataset_type}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing class...  0\n",
      "processing class...  1\n",
      "processing class...  2\n",
      "processing class...  3\n",
      "processing class...  4\n",
      "processing class...  5\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def process_class(i, count_train, count_validation, count_test):\n",
    "    print('processing class... ', i)\n",
    "    directory = f'{data_subfolder_name}/{str(i)}'\n",
    "    files = os.listdir(directory)\n",
    "    random.shuffle(files)\n",
    "\n",
    "    train_files = files[:count_train]\n",
    "    validation_files = files[count_train:count_train+count_validation]\n",
    "    test_files = files[count_train+count_validation:count_train+count_validation+count_test]\n",
    "\n",
    "    train_data = []\n",
    "    validation_data = []\n",
    "    test_data = []\n",
    "    \n",
    "    for file in train_files:\n",
    "        new_path = f'{data_subfolder_name}/{str(i)}/{file.replace(\":\", \"_\")}'\n",
    "        item_img = cv2.imread(new_path)\n",
    "        if grayscale is True:\n",
    "            item_img = cv2.cvtColor(item_img, cv2.COLOR_BGR2GRAY)\n",
    "            res = cv2.resize(item_img, dsize=image_dimensions, interpolation=cv2.INTER_CUBIC)\n",
    "            res = np.expand_dims(res, axis=-1)\n",
    "        else:\n",
    "            item_img = cv2.cvtColor(item_img, cv2.COLOR_BGR2RGB)\n",
    "            res = cv2.resize(item_img, dsize=image_dimensions, interpolation=cv2.INTER_CUBIC)\n",
    "        item_label = i\n",
    "        train_data.append((res, item_label))\n",
    "   \n",
    "    print(f'\\ttraining for {i} done...')\n",
    "    for file in validation_files:\n",
    "        new_path = f'{data_subfolder_name}/{str(i)}/{file.replace(\":\", \"_\")}'\n",
    "        item_img = cv2.imread(new_path)\n",
    "        if grayscale is True:\n",
    "            item_img = cv2.cvtColor(item_img, cv2.COLOR_BGR2GRAY)\n",
    "            res = cv2.resize(item_img, dsize=image_dimensions, interpolation=cv2.INTER_CUBIC)\n",
    "            res = np.expand_dims(res, axis=-1)\n",
    "        else:\n",
    "            item_img = cv2.cvtColor(item_img, cv2.COLOR_BGR2RGB)\n",
    "            res = cv2.resize(item_img, dsize=image_dimensions, interpolation=cv2.INTER_CUBIC)\n",
    "        item_label = i\n",
    "        validation_data.append((res, item_label))\n",
    "        \n",
    "    print(f'\\tvalidation for {i} done...')\n",
    "    for file in test_files:\n",
    "        new_path = f'{data_subfolder_name}/{str(i)}/{file.replace(\":\", \"_\")}'\n",
    "        item_img = cv2.imread(new_path)\n",
    "        if grayscale is True:\n",
    "            item_img = cv2.cvtColor(item_img, cv2.COLOR_BGR2GRAY)\n",
    "            res = cv2.resize(item_img, dsize=image_dimensions, interpolation=cv2.INTER_CUBIC)\n",
    "            res = np.expand_dims(res, axis=-1)\n",
    "        else:\n",
    "            item_img = cv2.cvtColor(item_img, cv2.COLOR_BGR2RGB)\n",
    "            res = cv2.resize(item_img, dsize=image_dimensions, interpolation=cv2.INTER_CUBIC)\n",
    "        item_label = i\n",
    "        test_data.append((res, item_label))\n",
    "    \n",
    "    print(f'\\ttest for {i} done...')\n",
    "    return train_data, validation_data, test_data\n",
    "\n",
    "def create_dataset_slice(count_train, count_validation, count_test):\n",
    "    train_data = []\n",
    "    validation_data = []\n",
    "    test_data = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=6) as executor:\n",
    "        futures = [executor.submit(process_class, i, count_train, count_validation, count_test) for i in range(6)]\n",
    "        \n",
    "        for future in futures:\n",
    "            t_data, v_data, te_data = future.result()\n",
    "            train_data.extend(t_data)\n",
    "            validation_data.extend(v_data)\n",
    "            test_data.extend(te_data)\n",
    "\n",
    "    random.shuffle(train_data)\n",
    "    random.shuffle(validation_data)\n",
    "    random.shuffle(test_data)\n",
    "\n",
    "    return train_data, validation_data, test_data\n",
    "\n",
    "train_set, validation_set, test_set = create_dataset_slice(train_set_size//6, validation_set_size//6, test_set_size//6)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving training set...\n",
      "Done!\n",
      "Saving validation set...\n",
      "Done!\n",
      "Saving test set...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "training_set_file_path = f\"./datasets/{training_presets_subfolder_name}/training_set.pkl\"\n",
    "validation_set_file_path = f\"./datasets/{training_presets_subfolder_name}/validation_set.pkl\"\n",
    "test_set_file_path = f\"./datasets/{training_presets_subfolder_name}/test_set.pkl\"\n",
    "\n",
    "with open(training_set_file_path, \"wb\") as file:\n",
    "    print('Saving training set...')\n",
    "    pickle.dump(train_set, file)\n",
    "    print('Done!')\n",
    "\n",
    "with open(validation_set_file_path, \"wb\") as file:\n",
    "    print('Saving validation set...')\n",
    "    pickle.dump(validation_set, file)\n",
    "    print('Done!')\n",
    "\n",
    "with open(test_set_file_path, \"wb\") as file:\n",
    "    print('Saving test set...')\n",
    "    pickle.dump(test_set, file)\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optional: Remove 'other' class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training set...\n",
      "Done!\n",
      "Loading validation set...\n",
      "Done!\n",
      "Loading test set...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "training_set_file_path = f\"./datasets/{training_presets_subfolder_name}/training_set.pkl\"\n",
    "validation_set_file_path = f\"./datasets/{training_presets_subfolder_name}/validation_set.pkl\"\n",
    "test_set_file_path = f\"./datasets/{training_presets_subfolder_name}/test_set.pkl\"\n",
    "\n",
    "with open(training_set_file_path, \"rb\") as file:\n",
    "  print('Loading training set...')\n",
    "  train_set = pickle.load(file)\n",
    "  print('Done!')\n",
    "  \n",
    "with open(validation_set_file_path, \"rb\") as file:\n",
    "  print('Loading validation set...')\n",
    "  validation_set = pickle.load(file)\n",
    "  print('Done!')\n",
    "  \n",
    "with open(test_set_file_path, \"rb\") as file:\n",
    "  print('Loading test set...')\n",
    "  test_set = pickle.load(file)\n",
    "  print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing training set...\n",
      "Done!\n",
      "Processing test set...\n",
      "Done!\n",
      "Processing validation set...\n",
      "Done!\n",
      "3096\n",
      "2580\n",
      "660\n",
      "550\n",
      "660\n",
      "550\n"
     ]
    }
   ],
   "source": [
    "train_set_without_other = []\n",
    "test_set_without_other = []\n",
    "validation_set_without_other = []\n",
    "\n",
    "print('Processing training set...')\n",
    "for sample in train_set:\n",
    "  if int(sample[1]) == 5:\n",
    "    continue\n",
    "  else:  \n",
    "    train_set_without_other.append(sample)\n",
    "print('Done!')\n",
    "    \n",
    "print('Processing test set...')\n",
    "for sample in test_set:\n",
    "  if int(sample[1]) == 5:\n",
    "    continue\n",
    "  else:  \n",
    "    test_set_without_other.append(sample)\n",
    "print('Done!')\n",
    "\n",
    "print('Processing validation set...')\n",
    "for sample in validation_set:\n",
    "  if int(sample[1]) == 5:\n",
    "    continue\n",
    "  else:  \n",
    "    validation_set_without_other.append(sample)    \n",
    "print('Done!') \n",
    "  \n",
    "print(len(train_set))\n",
    "print(len(train_set_without_other))\n",
    "\n",
    "print(len(validation_set))\n",
    "print(len(validation_set_without_other))\n",
    "\n",
    "print(len(test_set))\n",
    "print(len(test_set_without_other))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving training set...\n",
      "Done!\n",
      "Saving validation set...\n",
      "Done!\n",
      "Saving test set...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "training_set_file_path = f\"./datasets/{training_presets_subfolder_name}/training_set_NO_OTHER.pkl\"\n",
    "validation_set_file_path = f\"./datasets/{training_presets_subfolder_name}/validation_set_NO_OTHER.pkl\"\n",
    "test_set_file_path = f\"./datasets/{training_presets_subfolder_name}/test_set_NO_OTHER.pkl\"\n",
    "\n",
    "with open(training_set_file_path, \"wb\") as file:\n",
    "    print('Saving training set...')\n",
    "    pickle.dump(train_set_without_other, file)\n",
    "    print('Done!')\n",
    "\n",
    "with open(validation_set_file_path, \"wb\") as file:\n",
    "    print('Saving validation set...')\n",
    "    pickle.dump(validation_set_without_other, file)\n",
    "    print('Done!')\n",
    "\n",
    "with open(test_set_file_path, \"wb\") as file:\n",
    "    print('Saving test set...')\n",
    "    pickle.dump(test_set_without_other, file)\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optional: Turn Grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training set...\n",
      "Done!\n",
      "Loading validation set...\n",
      "Done!\n",
      "Loading test set...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "training_set_file_path = f\"./datasets/{training_presets_subfolder_name}/training_set.pkl\"\n",
    "validation_set_file_path = f\"./datasets/{training_presets_subfolder_name}/validation_set.pkl\"\n",
    "test_set_file_path = f\"./datasets/{training_presets_subfolder_name}/test_set.pkl\"\n",
    "\n",
    "with open(training_set_file_path, \"rb\") as file:\n",
    "  print('Loading training set...')\n",
    "  train_set = pickle.load(file)\n",
    "  print('Done!')\n",
    "  \n",
    "with open(validation_set_file_path, \"rb\") as file:\n",
    "  print('Loading validation set...')\n",
    "  validation_set = pickle.load(file)\n",
    "  print('Done!')\n",
    "  \n",
    "with open(test_set_file_path, \"rb\") as file:\n",
    "  print('Loading test set...')\n",
    "  test_set = pickle.load(file)\n",
    "  print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing training set...\n",
      "Done!\n",
      "Processing test set...\n",
      "Done!\n",
      "Processing validation set...\n",
      "Done!\n",
      "3096\n",
      "3096\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "train_set_grayscale = []\n",
    "test_set_grayscale = []\n",
    "validation_set_grayscale = []\n",
    "\n",
    "print('Processing training set...')\n",
    "for sample in train_set:\n",
    "  item_img = sample[0]\n",
    "  item_img = cv2.cvtColor(item_img, cv2.COLOR_BGR2GRAY)\n",
    "  res = cv2.resize(item_img, dsize=image_dimensions, interpolation=cv2.INTER_CUBIC)\n",
    "  res = np.expand_dims(res, axis=-1)\n",
    "  train_set_grayscale.append((res, sample[1]))\n",
    "print('Done!')\n",
    "    \n",
    "print('Processing test set...')\n",
    "for sample in test_set:\n",
    "  item_img = sample[0]\n",
    "  item_img = cv2.cvtColor(item_img, cv2.COLOR_BGR2GRAY)\n",
    "  res = cv2.resize(item_img, dsize=image_dimensions, interpolation=cv2.INTER_CUBIC)\n",
    "  res = np.expand_dims(res, axis=-1)\n",
    "  test_set_grayscale.append((res, sample[1]))\n",
    "print('Done!')\n",
    "\n",
    "print('Processing validation set...')\n",
    "for sample in validation_set:\n",
    "  item_img = sample[0]\n",
    "  item_img = cv2.cvtColor(item_img, cv2.COLOR_BGR2GRAY)\n",
    "  res = cv2.resize(item_img, dsize=image_dimensions, interpolation=cv2.INTER_CUBIC)\n",
    "  res = np.expand_dims(res, axis=-1)\n",
    "  validation_set_grayscale.append((res, sample[1]))\n",
    "print('Done!') \n",
    "\n",
    "print(len(train_set_grayscale))\n",
    "print(len(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving training set...\n",
      "Done!\n",
      "Saving validation set...\n",
      "Done!\n",
      "Saving test set...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "training_set_file_path = f\"./datasets/{training_presets_subfolder_name}/training_set_grayscale.pkl\"\n",
    "validation_set_file_path = f\"./datasets/{training_presets_subfolder_name}/validation_set_grayscale.pkl\"\n",
    "test_set_file_path = f\"./datasets/{training_presets_subfolder_name}/test_set_grayscale.pkl\"\n",
    "\n",
    "with open(training_set_file_path, \"wb\") as file:\n",
    "    print('Saving training set...')\n",
    "    pickle.dump(train_set_grayscale, file)\n",
    "    print('Done!')\n",
    "\n",
    "with open(validation_set_file_path, \"wb\") as file:\n",
    "    print('Saving validation set...')\n",
    "    pickle.dump(validation_set_grayscale, file)\n",
    "    print('Done!')\n",
    "\n",
    "with open(test_set_file_path, \"wb\") as file:\n",
    "    print('Saving test set...')\n",
    "    pickle.dump(test_set_grayscale, file)\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training set...\n",
      "Done!\n",
      "Loading validation set...\n",
      "Done!\n",
      "Loading test set...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "training_set_file_path = f\"./datasets/{training_presets_subfolder_name}/training_set.pkl\"\n",
    "validation_set_file_path = f\"./datasets/{training_presets_subfolder_name}/validation_set.pkl\"\n",
    "test_set_file_path = f\"./datasets/{training_presets_subfolder_name}/test_set.pkl\"\n",
    "\n",
    "with open(training_set_file_path, \"rb\") as file:\n",
    "  print('Loading training set...')\n",
    "  train_set = pickle.load(file)\n",
    "  print('Done!')\n",
    "  \n",
    "with open(validation_set_file_path, \"rb\") as file:\n",
    "  print('Loading validation set...')\n",
    "  validation_set = pickle.load(file)\n",
    "  print('Done!')\n",
    "  \n",
    "with open(test_set_file_path, \"rb\") as file:\n",
    "  print('Loading test set...')\n",
    "  test_set = pickle.load(file)\n",
    "  print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['495', '212', '260', '3106', '290', '147', '196', '491', '207', '125', '329', '220', '215', '245', '348', '178', '223', '411', '300', '168', '233', '626', '441', '195', '242', '119', '324', '469', '155', '370', '315', '249', '333', '335', '3221', '139', '232', '115', '183', '106', '667', '209', '452', '666', '352', '486', '246', '298', '357', '294', '465', '368', '380', '547', '201', '268', '108', '665', '314', '189', '358', '591', '103', '269', '259', '369', '261', '293', '595', '109', '533', '323', '534', '664', '419', '144', '193', '581', '278', '624', '413', '3155', '132', '433', '272', '107', '492', '310', '190', '142', '256', '216', '253', '460', '305', '304', '398', '301', '265', '317', '414', '213', '177', '214', '392', '267', '302', '295', '663', '575', '264', '475', '403', '217', '322', '130', '137', '316', '427', '231', '118', '281', '237', '211', '346', '250', '172', '397', '224', '126', '668', '262', '270', '483', '421', '381', '243', '194', '538', '351', '258', '405']\n",
      "0 -> 13\n",
      "1 -> 34\n",
      "2 -> 21\n",
      "3 -> 32\n",
      "4 -> 15\n",
      "5 -> 27\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import json\n",
    "\n",
    "all_labels = [label for _, label in train_set] + [label for _, label in validation_set] + [label for _, label in test_set]\n",
    "all_labels = list(set(all_labels))\n",
    "\n",
    "print(all_labels)\n",
    "category_dict = {\n",
    "  0: [],\n",
    "  1: [],\n",
    "  2: [],\n",
    "  3: [],\n",
    "  4: [],\n",
    "  5: []\n",
    "}\n",
    "category_dict_reversed = {}\n",
    "\n",
    "with open('../../fastener_dataset/annotations/instances_default.json', 'r') as file:\n",
    "  annotations = json.load(file)\n",
    "  annotations = annotations['annotations']\n",
    "  for label in all_labels:\n",
    "    for annotation in annotations:\n",
    "      if int(annotation['attributes']['category']) == int(label):\n",
    "        if category_dict_reversed.get(int(label)) is None:\n",
    "          category_dict_reversed[int(label)] = []\n",
    "        # print(f\"Label: {label}, ID: {annotation['category_id']}\")\n",
    "        category_dict[int(annotation['category_id']) - 1].append(int(label))\n",
    "        category_dict_reversed[int(label)].append(int(annotation['category_id']) - 1)\n",
    "  \n",
    "for key in category_dict_reversed.keys():\n",
    "  category_dict_reversed[key] = list(set(category_dict_reversed[key]))\n",
    "  if len(category_dict_reversed[key]) != 1:\n",
    "    print(f'Warning!: {key} -> {category_dict_reversed[key]}')\n",
    "  category_dict_reversed[key] = category_dict_reversed[key][0]\n",
    "  \n",
    "for key in category_dict.keys():\n",
    "  category_dict[key] = list(set(category_dict[key]))\n",
    "  print(f'{key} -> {len(category_dict[key])}')\n",
    "\n",
    "with open('./datasets/categories.json', 'w') as file:\n",
    "  file.write(json.dumps(category_dict))\n",
    "  \n",
    "with open('./datasets/categories_inverse.json', 'w') as file:\n",
    "  file.write(json.dumps(category_dict_reversed))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
